[{"time":"9.00am - 10.30am","groups":[[{"lecturer":"Lorenzo Rossi and Paolo Santorio","title":"Trivalent and Dynamic Theories of Conditionals","group":"Introductory","description":"The course explores two families of theories of indicative conditionals: trivalent and dynamic/informational semantics. We start by introducing trivalent and dynamic theories of conditionals, making reference to both classical and contemporary work. We then introduce puzzles relating conditionals and probability and Stalnaker's Thesis, i.e. the claim that probabilities of conditionals are conditional probabilities. We show how both trivalent and dynamic approaches can offer solutions to these puzzles. Trivalent theories vindicate Stalnaker's Thesis while avoiding some of its paradoxical consequences, and are simple and workable. Dynamic theories can be combined with theories of probability in a way to vindicate Stalnaker's Thesis, and at the same time are well-integrated with a compositional semantics for modality in natural language. Yet both theories have open problems. We conclude by exploring a hybrid approach, which exploits the fact that the notion of support at the core of dynamic semantics is inherently partial.\nThe course will be taught at an introductory level.","id":"1-0"},{"lecturer":"Deniz Özyıldız and Ciyang Qing","title":"Semantic properties and combinatorial restrictions of attitude predicates","group":"Advanced","description":"This course is about two types of properties of  attitude predicates: combinatorial properties, i.e., the types of clauses they can be combined with, and semantic properties, e.g., veridicality, neg-raising, preferentiality, focus-sensitivity and event-structural properties. In particular, it concentrates on the extent to which the combinatorial properties can be explained by the semantic properties, a topic under active research with many established results and open empirical, theoretical, and methodological issues.\nWe present empirical generalizations and theoretical analyses in the literature, review recent debates about their validity, and discuss several refinements and extensions. In this process, we illustrate how experimental, corpus, as well as crosslinguistic data, when combined with insights from formal theoretical analyses, can deepen our understanding of the internal meaning components of attitude verbs and how these components give rise to certain syntactic patterns. The resulting analyses pave the way for uncovering novel syntactic-semantic universals for attitude verbs.","id":"1-1"}],[{"lecturer":"Antonio Toral and Arianna Bisazza","title":"Neural Machine Translation","group":"Introductory","description":"In this course students will be introduced to machine translation (MT): a field that investigates the use of software to translate text automatically between different languages. The course provides an overview of this field and focuses on the currently dominating paradigm in MT, which uses neural networks (NNs). Students will be introduced to the main NN architectures used in MT, which are also commonly used in other sequence-to-sequence language tasks (e.g. text summarisation). The course will also cover the evaluation of MT systems, the use of linguistic knowledge in MT systems, unsupervised approaches to MT, and different uses of MT systems in the wider society together with the implications thereof.","id":"1-2"},{"lecturer":"Gasper Begus","title":"Deep Language Learning: Modeling language from raw speech","group":"Advanced","description":"For the first time in history, we can model language from raw speech in a fully unsupervised manner. Using deep generative models trained on speech, we can model phonetic, phonological, morphological, and even basic syntactic and lexical semantic learning.  This course will introduce students to deep learning and techniques to uncover linguistically meaningful representations in deep neural networks trained on raw speech. We will focus on convolutional neural networks, an architecture that is  inspired by biological neural processing and has seen many applications in visual and audio processing. We will learn to train a generative adversarial network on spoken language, find disentangled causal structure in the hidden space of these networks, introspect their intermediate representations, and use these outputs for language modeling. Understanding how deep neural networks learn has consequences both for linguistic theory and cognitive science as well as for building interpretable machine learning.","id":"1-3"}],[{"lecturer":"Tobias Kappé","title":"Elements of Kleene Algebra","group":"Foundational","description":"You have most likely been exposed to a fair amount of equational reasoning, whether it was used to apply Newton's laws or to manipulate polynomials. But the principles behind this approach are not limited to numbers: this course provides an introduction to Kleene Algebra, an equational approach to specify and reason about sequences of events with applications ranging from pattern matching to program verification using propositional Hoare logic.\nThe material covered will focus primarily on the logical and computational aspects of Kleene Algebra. We will cover Kozen's completeness theorem, which says that any true equivalence of regular expressions can be proved, as well as its intricate connection to Kleene's theorem, which relates regular expressions to finite automata. Along the way, we will encounter some elegant mathematical constructions, such as Brzozowski's derivatives, as well as useful extensions of the core calculus, including Kleene Algebra with Tests.","id":"1-4"},{"lecturer":"Luca Geatti and Angelo Montanari","title":"The Safety Fragment of Temporal Logics of Infinite Sequences","group":"Introductory","description":"In AI and Formal Verification, temporal logics of infinite sequences are extensively used to model, verify, and synthesize hardware and software systems. An important class of them is the safety fragment, that expresses the fact that “something bad never happens”. Languages in this class are such that a prefix of a sequence suffices to establish whether it belongs or not to the language, allowing to reason over finite sequences. The course focuses on such a safety fragment. It defines it, studies its formalizations in terms of first-order logic, temporal logic, and automata, and explores its relationships with the Temporal Hierarchy. Then, it investigates its computational properties, in terms of both worst-case complexity and efficient algorithms for model checking and synthesis. Finally, it discusses succinctness issues.","id":"1-5"}],[]]},{"time":"10.30am - 11.00am","groups":[],"title":"coffee break"},{"time":"11.00am - 12.30pm","groups":[[{"lecturer":"Salvatore Florio and Carlo Nicolai","title":"Formal Theories of Properties","group":"Introductory","description":"This course is an introduction to formal theories of properties, where these include propositions as well as relations. We motivate the foundational importance of properties across disciplines and the need for formal models. We then review different ways of developing formal theories of properties, corresponding to different logical and metaphysical choices. Finally, we assess the costs and benefits of various theories. Our discussion includes a survey of classic contributions as well as recent developments in the area.","id":"1-6"},{"lecturer":"Giuseppe Sanfilippo","title":"Logical Operations Among Conditionals as Conditional Random Quantities","group":"Advanced","description":"Giuseppe Sanfilippo Abstract\nIn the subjectivistic theory, the probability P(E) measure the degree of belief on E being true. The consistency of the probability assessments is guaranteed by a coherence principle. All basic probabilistic properties follow from coherence. A large number of philosophers and psychologists assume valid that the probability of a natural language conditional, P(if H then A), coincides with the conditional subjective probability P(A|H) of the conditional event A|H. Usually, a conditional event is looked at as a three-valued object and compound conditionals have been defined in trivalent logics. We verify that none of these logics satisfies all the basic probabilistic properties valid for unconditional events. Then, we consider an approach to compound conditionals in the setting of conditional random quantities. We verify that all the basic logical and probabilistic properties are preserved and  we illustrate applications to the psychology of uncertain reasoning, to connexive logic and to non-monotonic reasoning.","id":"1-7"}],[{"lecturer":"Kata Balogh and Simon Petitjean","title":"Tree-Adjoining Grammars: Theory and implementation","group":"Introductory","description":"This course provides an introduction into the Tree-Adjoining Grammar (TAG) formalism, in particular Lexicalized Tree-Adjoining Grammar (LTAG), together with grammar implementations and tools for parsing with TAG: XMG and TuLiPA. During the course we will show the importance of TAG and related formalisms in computational linguistics, providing syntactic and semantic analyses of different linguistic phenomena, as well as introducing implementations that show the adequacy of the formalism for natural language analysis.","id":"1-8"},{"lecturer":"Enrica Troiano and Valerio Basile","title":"Data Perspectivism in Computational Linguistics","group":"Advanced","description":"The creation of resources for Natural Language Processing (NLP) typically involves human participants. Presented with some verbal material, independent annotators express their personal understanding of a given linguistic phenomenon. The judgments they provide often have tremendous internal variability: language is ambiguous, and its comprehension subjective, in such a way that multiple interpretations can hold for the same piece of data. In this light, putting into sharp focus how to deal with annotation disagreements is of paramount importance for any data collection activity, to clarify when humans' divergent views affect the quality of the final resource or rather represent different (yet all legitimate) text understanding perspectives.\nThis course will introduce students to the \"perspectivist\" approach to data collection, i.e., one that embraces the diversity of human annotations. It will cover potential sources of disagreement to consider when designing annotation schemes, strategies to evaluate the quality of data in a perspectivist framework, as well as methods to make use of disagreements for learning automatic models.","id":"1-9"}],[{"lecturer":"Francesca Poggiolesi","title":"Proofs and explanations","group":"Introductory","description":"Amongst the several types of existing explanations, in the last decade philosophers have become receptive to the so called non causal or conceptual explanations. Conceptual explanations do not derive their explanatory power from a network of causal relations, but rather from a network of conceptual relations. Thus, conceptual explanations are prime facie a natural object for logical analysis. A rising amount of work has been dedicated to the application of proof-theoretical methods to formalise the notion of conceptual explanation: this work not only combines well-known proof-theoretic techniques, such as cut-elimination or normalization, with a deep philosophical analysis, but also it has introduced in logic the notion of explanation, a notion which has been so far largely neglected. The goal of this course is to make the student acquainted with the notion of conceptual explanation together with the proof-theoretic method used for its formalization.","id":"1-10"},{"lecturer":"Alessio Mansutti and Christoph Haase","title":"Linear arithmetic theories: algorithms and applications","group":"Advanced","description":"Arithmetic theories are logical theories for reasoning about number systems. They find several applications across computer science, including in verification, AI and compiler op- timisation. The foundations of arithmetic theories lie at the interface of logic, geometry and automata theory.\nThis course is an introduction to linear arithmetic theories, with an emphasis on Pres- burger arithmetic, the first-order theory of the integers with addition and order. We start by exploring the subject bottom up, introducing linear arithmetic theories with problems coming from optimisation and AI. Subsequently, we cover classic algorithms for linear and integer programming. The last three lectures focus on three algorithmic paradigms to decide Presburger arithmetic based on quantifier elimination, finite-state automata, and geometric decision procedures. We emphasise differences between these techniques by studying exten- sions of Presburger arithmetic that can be tackled in a natural way only within one of the three. We also demonstrate software offering support for these paradigms: RedLog (quan- tifier elimination), Walnut (finite-state automata), and SageMath (geometric procedures","id":"1-11"}],[{"lecturer":"Milica Denić","title":"Workshop on Internal and external pressures shaping language","group":"Workshop","website":"https://sites.google.com/view/iepsl-esslli2023workshop/","description":"Human languages vary in their phonology, morphosyntax and semantics, but there are important constraints on this variation. What explains these typological similarities and differences across languages? Recent work has combined tools from linguistics, cognitive psychology and computer science to address this question. In addition to empirical discoveries, this has led to novel hypotheses for how similarities and differences are to be accounted for, invoking internal (e.g. cognitive) and/or external (e.g. communicative, historical, geographical) pressures on language structure. The aims of the workshop are two-fold: (i) expand the knowledge of different internal and external pressures on language, and how they explain cross-linguistic similarities and differences in different aspects of language structure, (ii) invite a critical discussion of implications of this work for the study of human cognition more generally.","id":"1-12"}]]},{"time":"12.30pm - 2.00pm","groups":[],"title":"lunch"},{"time":"2.00pm - 3.30pm","groups":[[{"lecturer":"Merel Semeijn and Louis Rouillé","title":"Let’s talk about Frodo: An Introduction to the Semantics of Fiction","group":"Introductory","description":"Providing a semantic theory that applies to both serious and fictional uses of language is challenging. Fiction is about pretence, or make-believe: when we produce or interpret a fictional text, we typically read fictional statements as if they were true by imagining a fictional world. A good semantics of fiction should model how this pretence component operates both at the sentential level (what is \"truth in the fiction\" as opposed to truth simpliciter?) and at the level of reference (what is the semantic contribution of a fictional name as opposed to a real name?). This course will take students into the very active and growing area of research today concerned with providing a good semantics of fiction. This field contains many open problems. It is essentially interdisciplinary (at the intersection of philosophy of language, formal linguistics, logic and literary studies) and it questions the foundations of our best semantic theories.","id":"1-13"},{"lecturer":"Keny Chatain and Benjamin Spector","title":"Current topics in the semantics and pragmatics of plural expressions","group":"Advanced","description":"What is the meaning of plural expressions in natural languages: \"the students\", \"some apples\", etc? While the answer to such questions seems pretty straightforward at first sight, appearances are deceptive. It turns out that providing a unified and empirically adequate theory of the meaning of plural expressions  in various syntactic environments is surprisingly difficult.\nThe goal of this class is to introduce students to one major approach to plural semantics, based on the the idea that plural expressions denote or quantify over so-called \"plural individuals\", and to present some recent research within this framework which aim to address puzzles pertaining to the interpretation of numerals and plural definites. The discussion will contain the presentation of formal models, a detailed investigation of their predictions, as well as data coming from experimental semantics. We will cover topics such as:\n- The various types of readings that plural expressions can trigger depending on the type of predicate they combine with (collective readings, distributive readings, cumulative) - Typology of collective predicates (gather/numerous) - Maximality in the semantics of plural quantifiers (all, modified numerals) and its interaction with predicate types - Homogeneity and non-maximality","id":"1-14"}],[{"lecturer":"Mehrnoosh Sadrzadeh and Gijs Wijnholds","title":"Natural Language Syntax and Statistical Semantics with Modal Lambek Calculus","group":"Introductory","description":"The Lambek Calculus models natural language grammar as a logic, rejecting the rules of commutativity, associativity, contraction and weakening. Controlled versions of these rules can be added via modalities and the resulting logic is known as Modal Lambek Calculus. Modal Lambek Calculus has a compositional interface to natural language semantics: to possible worlds via ternary frames, and to vector representations via  algebraic constructions over syntax.\nThis course has two parts. The first part covers the core methodology behind the  modelling with Lambek Calculus and its modal extensions; we derive examples of syntactic constructions and analyse their semantics. After that, we focus on the vector semantics and  show how they are learnt via statistical machine learning, applying the results to semantic similarity and disambiguation tasks. Along the way, we offer the possibility to work with user-friendly tools that produce syntactic derivations and compute statistical representations, and datasets for empirical validations/applications.","id":"1-15"},{"lecturer":"Michael Roth","title":"Limitations in NLP: Disagreements, Misunderstandings, and other Challenges","group":"Advanced","description":"Most approaches to natural language processing assume that language is consistently unambiguous: there is always only one right answer to a question, each sentence has exactly one specific meaning, and text classification tasks generally have only one correct solution. But do these assumptions really hold up in reality? A growing body of research is examining the fact that questions can be answered differently, texts can be understood in various ways, and annotators in general can have conflicting opinions.\nIn this advanced course, we will take a closer look at some of the difficulties that arise from the inherent ambiguity of language. In the first half of the course, we will introduce different types of challenges and corresponding tasks proposed in the literature. In the second half of the course, we will discuss possible solutions from recent research as well as natural limitations that might remain for computational models of language.","id":"1-16"}],[{"lecturer":"Aleks Knoks and Eric Pacuit","title":"Tools for Formal Epistemology: Doxastic Logic, Probability and Default Logic","group":"Foundational","description":"Logicians, philosophers, and artificial intelligence researchers interested in epistemic questions---or, roughly, questions relating to belief, knowledge, and reasoning---have developed formal models to refine these questions and to answer them. This course will introduce three of the most prominent such formal models: doxastic logic, Bayesian models, and default logic. We will introduce these models, highlighting their similarities and differences, as well as their advantages and pitfalls. The course will touch on the fundamental questions driving much of the research in formal epistemology. In addition to presenting the different models, we will discuss such issues as the lottery and preface paradoxes, doxastic paradoxes, the source of epistemic normativity, and puzzles associated with higher-order evidence and peer disagreement.","id":"1-17"},{"lecturer":"Valentin Goranko and Dmitry Shkatov","title":"First-order Modal and Temporal Logics: Philosophical and Computational Aspects","website":"https://www2.philosophy.su.se/goranko/Courses2023/ESSLLI2023.html","group":"Advanced","description":"This course will introduce languages, models, main types of semantics, and deductive systems for first-order modal and temporal logics.  It will discuss the philosophical problems arising in the interaction of quantification with modality and temporality and will then present an overview of technical results on completeness and incompleteness, decidability and undecidability, as well as algorithmic and computational complexity of the decision problems for some important systems of first-order modal and temporal logics.  Applications to philosophy, mathematics, and computer science will be briefly discussed.\nThe course is intended for a broad audience of graduate students interested in logical, philosophical, and computational aspects of modal and temporal reasoning.\n<b>Course material:</b><ul style=\"margin-left: 2em;\"><li><a href=\"https://www2.philosophy.su.se/goranko/Courses2023/ESSLLI2023.html\" target=\"_blank\">Course website</a></li></ul>","id":"1-24"}]]},{"time":"3.30pm - 3.50pm","groups":[],"title":"coffee break"},{"time":"3.50pm - 4.50pm","groups":[],"title":"Student Session (StuS)", "link": "courses-workshops-accepted/student-session-call.html"},{"time":"5.00pm - 6.30pm","groups":[[{"lecturer":"Peter Fritz","title":"Propositional Quantifiers","group":"Introductory","description":"Propositional quantifiers are quantifiers binding variables in the position of sentences. For instance, when added to standard propositional logic, they allow us to express the claim that for every proposition p, there is a proposition q such that p is materially equivalent to the negation of q.\nThis course will focus on propositional quantifiers in the context of modal logics, where they are especially useful. For example, in the context of a doxastic interpretation of modal logic, they allow us to make generalizations about what is and is not believed by an agent. With this, we can state that everything the agent believes is the case, that the agent believes that they believe something false, or that everything believed by one agent is believed by a second agent.\nStandard possible world models for modal logics can be extended straightforwardly to propositional quantifiers, by letting these quantifiers range over arbitrary sets of worlds. However, in many cases, this straightforward model theory leads to logics which are not recursively axiomatizable. In addition to these simple models, we will therefore consider a range of alternative models, including models based on complete Boolean algebras, and possible worlds models in which propositional quantifiers range over a restricted domain of sets of worlds.\nThe aim of the course is to show the usefulness of propositional quantifiers in modal logics using examples, to provide a systematic overview of the work that has been done in this field, and to highlight some of the many interesting questions which remain open.\nThe course level will be Introductory.","id":"1-19"},{"lecturer":"Yoad Winter","title":"The Semantics of Reciprocity","group":"Advanced","description":"The proposed course will provide an overview of reciprocity from logical and (cross-)linguistic perspectives. After a short introduction to the formal semantics of plurals, the first part of the course will analyze meanings of reciprocal quantifiers (‘each other’). We will address their cross-linguistic relations with distributivity and collectivity, anaphora and reflexivity, and analyze pragmatic and lexical effects on their selection. The second part of the course will discuss reciprocal predicates (‘meet’, ‘hug’, ‘friend’), their logical effects on symmetry of n-ary relational meanings, and conceptual interactions with events and thematic roles. Overall, the proposed course will serve as an up-to-date example of the heterogeneity of formal semantics, illustrating its development from a subfield of philosophical logic to an interdisciplinary domain in linguistics that also engages with syntactic theory, lexical and typological analysis, and psycholinguistics.\n<b>Course material:</b><ul style=\"margin-left: 2em;\"><li><a href=\"https://www.phil.uu.nl/~yoad/esslli2023-course.pdf\" target=\"_blank\">Course slides</a></li></ul>","id":"1-20"}],[{"lecturer":"Eric Pacuit","title":"Computational Game Theory in Julia","group":"Introductory","description":"There are two objectives for this course. The first objective is to introduce the Julia programming language, with a special focus on developing programs to study game theory using the Agents.jl package (https://juliadynamics.github.io/Agents.jl) and the GameTheory.jl package (https://quantecon.github.io/GameTheory.jl). The second objective is to provide an introduction to game theory emphasizing issues of particular relevance to students at ESSLLI, such as signaling games and repeated games on networks. The course will include a number of tutorials that will give students hands-on experience writing Julia programs. No previous experience with the Julia programming language will be assumed.","id":"1-21"},{"lecturer":"Kyle Richardson and Vivek Srikumar","title":"Formal Techniques for Neural-symbolic Modeling","group":"Advanced","description":"This is intended to be an advanced course on current methods for combining symbolic logic and neural networks, with applications to problems in natural language processing (NLP). In particular, we focus on techniques that use  symbolic knowledge and declarative constraints to train machine learning models by compiling the corresponding symbolic logic into a differentiable form, also known as the logic as a loss function family of approaches. Details of current approach in NLP, as well as the formal and algorithmic techniques needed to doing this, will be covered in detail and drawn from the broader literature of neural-symbolic learning and reasoning.","id":"1-22"}],[{"lecturer":"Wesley Holliday","title":"Possibility Semantics","group":"Introductory","description":"Possibility Semantics is a generalization of Possible World Semantics, based on partial possibilities instead of complete possible worlds. In recent years, this approach has been applied to the semantics of modal and non-classical logics, natural language semantics, and semi-constructive mathematics. In this course, we will provide: a more accessible introduction to Possibility Semantics than is available in the technical literature (Day 1); in-depth sample applications of Possibility Semantics to the modeling of knowledge and awareness (Day 2), the formal semantics of epistemic modals in natural language (Day 3), and temporal logic and the openness of the future (Day 4); and an introduction to propositional and first-order quantification in possibility semantics (Day 5). No previous familiarity with Possibility Semantics will be assumed. Over the course of the week, we will suggest a number of open problems and avenues for future research.","id":"1-23"},{"lecturer":"Brian Logan","title":"Logics for Safe AI","group":"Advanced","description":"This advanced course will introduce the use of logics for the specification, verification and synthesis of provably correct AI programs. The topics will range from verification of multi-agent systems, synthesis of strategies for coalitions of agents, the use of logic in ensuring safety properties in reinforcement learning, and synthesising reward functions in reinforcement learning from logical specifications.","id":"1-18"},{"lecturer":"Nebojša Ikodinović and Dragan Doder","title":"Logics with Probability Operators and Quantifiers","group":"Advanced","description":"Many formalisms for representing, and reasoning with, uncertain knowledge are based on probabilistic logics that extend classical logic calculus with probability operators or quantifiers. The main goal of this course is to provide a solid foundation for students that want to use results and ideas from probabilistic logics  in their own field of study. We will introduce inductive logic, predicate logic with probability quantifiers and several logics with probability operators through a variety of examples from different fields (philosophy, decision theory, artificial intelligence, game theory etc.), and a more detailed presentation of related research problems (Specify some principles of rational belief and find their mathematical representation; Investigate logical consequence of the law of large number; Axiomatize propositional logic related to Markov processes). We will present an overview of main results and show that all those approaches are essentially connected. We will also present probabilistic extensions of various other logic systems.","id":"1-25"}],[{"lecturer":"Sonia Ramotowska and Fabian Schlotterbeck","title":"Procedural and computational models of semantic and pragmatic processes","group":"Workshop","website":"https://prosandcomps.github.io/","description":"Procedural and computational modeling frameworks have been applied successfully to various aspects of semantic and pragmatic processes, yielding not only a good fit to empirical data but also insights of theoretical relevance. On the one hand, computational (e.g., Bayesian or information theoretic) models rationalize speaker behavior and explain how the listener can use the given information efficiently to infer the intended meaning from an utterance. However, these models often leave the stepwise processing of linguistic information unspecified. On the other hand, procedural procedural (e.g., automata or ACT-R) models explain step-by-step cognitive processes behind meaning-related computations e.g., the process of building sentence representations. However, they often lack the means to combine different information types in an interactive fashion. The goal of this workshop is to bring together researchers applying these two modeling methodologies to discuss their strengths and weaknesses and work towards an integrated approach.","id":"1-26"}]]}]
